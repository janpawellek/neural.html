<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>neural.html</title>
    </head>
    <body>
        <div id="main">
            <h1>neural.html</h1>
            <h2>A Neural Network that lives in a single HTML page.</h2>
            <p>
                Please inspect the source code of this page. You will find a neural network implementation in JavaScript
                and some examples to be run as JavaScript commands, e.g. in the JavaScript console.
            </p>
            <p>
                Furthermore here are some interactive examples:
            </p>

            <h3>Learning AND</h3>
            <textarea id="ex1-textarea" style="width: 100%; height: 350px;">
var samples = [
    [[0, 0], [0]],
    [[1, 1], [1]],
    [[0, 1], [0]],
    [[1, 1], [1]],
    [[1, 0], [0]],
    [[1, 1], [1]]
];
var nn = Object.create(NeuralNetwork),
    N = 1000,
    lambda = 0.0,
    tau = 0.1,
    mu = 0.5;
nn.init(2, 1);
nn.setActivationFunction(ActivationFunctions.sigmoid);
nn.learning(N, samples, lambda, tau, mu);
document.getElementById('ex1-output').innerHTML =
    'Result:<br>' +
    '0 AND 0 is ' + Math.round(nn.forward([0,0])) + '<br>' +
    '0 AND 1 is ' + Math.round(nn.forward([0,1])) + '<br>' +
    '1 AND 0 is ' + Math.round(nn.forward([1,0])) + '<br>' +
    '1 AND 1 is ' + Math.round(nn.forward([1,1])) + '<br>';</textarea>
            <button id="ex1-button">Run code</button>
            <div id="ex1-output"></div>

            <h3>Learning a cosine function</h3>
            <textarea id="ex2-textarea" style="width: 100%; height: 250px">
var nn = Object.create(NeuralNetwork),
    N = 1000,
    lambda = 0.1,
    tau = 0.01,
    mu = 0.5,
    samples = [],
    i,
    j;
for (i = 0, j = 0; i < 7; i += 0.01, j++) {
    samples[j] = [[i], [0.5*(Math.cos(i)+1)]];
}
nn.init(1, 20, 5, 1);
nn.setActivationFunction(ActivationFunctions.sigmoid);
nn.learning(N, samples, lambda, tau, mu);</textarea>
            <button id="ex2-button">Run code</button><br>
            <canvas id="ex2-output" style="width: 100%; height: 300px; display: none;"></canvas>
        </div>

        <h3>Classification</h3>
        <textarea id="ex3-textarea" style="width: 100%; height: 150px">
var nn = Object.create(NeuralNetwork),
    N = 1000,
    lambda = 0.1,
    tau = 0.01,
    mu = 0.5,
    softmax = true;
nn.init(2, 2, 2, numCategories);
nn.setActivationFunction(ActivationFunctions.sigmoid);
nn.learning(N, trainingset_onehot, lambda, tau, mu);</textarea><br>
        <label for="ex3-file">Select a file to start learning:</label>
        <input id="ex3-file" type="file" /><br>
        <canvas id="ex3-output" style="width: 100%; height: 300px; display: none;"></canvas>
        <div id="ex3-result"></div>

        <!-- Main code for a Neural Network in JavaScript -->
        <script>
            "use strict";
            var HelperFunctions,
                ActivationFunctions,
                Layer,
                NeuralNetwork,
                Tests;

            // Object that stores some helper functions
            HelperFunctions = {
                // calculates the outer product ab^T for two vectors a and b
                outerProduct: function(a, b) {
                    var n,
                        p,
                        result = new Array(a.length);
                    for (n = 0; n < a.length; n++) {
                        result[n] = new Array(b.length);
                        for (p = 0; p < b.length; p++) {
                            result[n][p] = a[n] * b[p];
                        }
                    }
                    return result;
                },

                // calculates the inner product a^Tb for a matrix a and a vector b
                innerProduct: function(a, b) {
                    var n,
                        p,
                        result = new Array(a[0].length);
                    for (n = 0; n < a[0].length; n++) {
                        result[n] = 0;
                        for (p = 0; p < b.length; p++) {
                            result[n] += a[p][n] * b[p];
                        }
                    }
                    return result;
                }
            };

            // Object that stores different activation functions
            ActivationFunctions = {
                sigmoid: {
                    calc: function(x) {
                        return 1 / (1 + Math.exp(-x));
                    },
                    derivative: function(x) {
                        var t = ActivationFunctions.sigmoid.calc(x);
                        return t * (1-t);
                    }
                },
                relu: {
                    calc: function(x) {
                        return Math.max(0, x);
                    },
                    derivative: function(x) {
                        if (x >= 0) {
                            return 1;
                        }
                        else {
                            return 0;
                        }
                    }
                }
            };

            // Object that encapsulates a single Layer of the neural network
            Layer = {
                // Initializes the layer with random values
                init: function(inputSize, outputSize) {
                    var i,
                        j;

                    this.inputSize = inputSize; // i
                    this.outputSize = outputSize; // j

                    // init W_j,i matrix with random values
                    this.w = [];
                    for (j = 0; j < outputSize; j++) {
                        this.w[j] = [];
                        for (i = 0; i < inputSize; i++) {
                            this.w[j][i] = Math.random() * 0.2 - 0.1;
                        }
                    }

                    // init b_j to zero
                    this.b = [];
                    for (j = 0; j < outputSize; j++) {
                        this.b[j] = Math.random() * 0.2 - 0.1;
                    }

                    // set default activation function
                    this.setActivationFunction(ActivationFunctions.relu);
                },

                // Sets an activation function
                setActivationFunction: function(phi) {
                    this.phi = phi;
                },

                // Calculate intermediate values (x-tilde)
                calculateIntermediates: function(input) {
                    var i,
                        j,
                        intermediates = [];

                    if (input.length !== this.inputSize) {
                        throw new Error('Expected input of size ' + this.inputSize + ', got input of size ' + input.length + '.');
                    }

                    for (j = 0; j < this.outputSize; j++) {
                        intermediates[j] = 0;
                        for (i = 0; i < this.inputSize; i++) {
                            intermediates[j] += this.w[j][i] * input[i];
                        }
                        intermediates[j] += this.b[j];
                    }

                    // store input and intermediates
                    this.input = input;
                    this.intermediates = intermediates;

                    return intermediates;
                },

                // Forward propagation
                forward: function(input) {
                    var j,
                        intermediates = this.calculateIntermediates(input),
                        output = [];
                    for (j = 0; j < this.outputSize; j++) {
                        output[j] = this.phi.calc(intermediates[j]);
                    }
                    return output;
                },

                // Back propagation
                back: function(v) {
                    var j,
                        intermediates = this.intermediates,
                        phiv = [];

                    if (v.length !== this.outputSize) {
                        throw new Error('Expected error vector of size ' + this.outputSize + ', got size ' + v.length + '.');
                    }
                    if (!this.input) {
                        throw new Error('Please run the forward propagation first.');
                    }

                    // 0. Calculate the Hadamard product of phi' and v ("phiv")
                    for (j = 0; j < this.outputSize; j++) {
                        phiv[j] = this.phi.derivative(intermediates[j]) * v[j];
                    }

                    // 1. Calculate dW
                    this.dW = HelperFunctions.outerProduct(phiv, this.input);

                    // 2. Calculate db
                    this.db = phiv;

                    // Propagate error
                    return HelperFunctions.innerProduct(this.w, phiv);
                },

                // Parameter update
                update: function(tau) {
                    var i,
                        j,
                        wnew,
                        bnew;

                    wnew = new Array(this.outputSize);
                    for (j = 0; j < this.outputSize; j++) {
                        wnew[j] = new Array(this.inputSize);
                        for (i = 0; i < this.inputSize; i++) {
                            wnew[j][i] = this.w[j][i] - (tau * this.dW[j][i]);
                        }
                    }
                    this.w = wnew;

                    bnew = new Array(this.outputSize);
                    for (j = 0; j < this.outputSize; j++) {
                        bnew[j] = this.b[j] - (tau * this.db[j]);
                    }
                    this.b = bnew;
                },

                // Backup parameters
                // Note: This only saves references. It works for the update() function
                // which creates new arrays but won't prevent you from changing the existing arrays.
                backup: function() {
                    this.backupData = {};
                    this.backupData.w = this.w;
                    this.backupData.b = this.b;
                },

                // Parameter update undo
                undo: function() {
                    this.w = this.backupData.w;
                    this.b = this.backupData.b;
                },

                // Perform regularization of dW
                regularization: function(l, lambda) {
                    var i,
                        j,
                        regularizationTerm;

                    regularizationTerm = function(x) {
                        // L1 regularization
                        if (l === 1) {
                            return x;
                        }
                        // L2 regularization
                        if (l === 2) {
                            return 1 / Math.sqrt(Math.pow(x, 2) + 0.0001);
                        }
                        throw new Error('Only L1 and L2 regularization is implemented.')
                    };

                    for (j = 0; j < this.outputSize; j++) {
                        for (i = 0; i < this.inputSize; i++) {
                            this.dW[j][i] += lambda * regularizationTerm(this.w[j][i]);
                        }
                    }
                }
            };

            NeuralNetwork = {
                // Set up a new neural network.
                // Specify the sizes of the layers as arguments to this function.
                // The first argument is the size of the input.
                // e.g.: nn.init(1, 2, 1)
                init: function() {
                    var k;

                    if (arguments.length < 2) {
                        throw new Error('You need to specify at least the input size and the size of one layer.');
                    }

                    this.layers = new Array(arguments.length - 1);
                    for (k = 1; k < arguments.length; k++) {
                        this.layers[k-1] = Object.create(Layer);
                        this.layers[k-1].init(arguments[k-1], arguments[k]);
                    }

                    console.log('Initialized a neural network with ' + (k-1) + ' layers:');
                    console.log(this.layers);
                },

                // Sets an activation function for every layer
                setActivationFunction: function(phi) {
                    if (!this.layers) {
                        throw new Error('You need to initialize the neural network first.');
                    }

                    this.layers.forEach(function(layer) {
                        layer.setActivationFunction(phi);
                    });
                },

                // Forward propagation
                forward: function(input) {
                    var k,
                        outputs = [];

                    if (!this.layers) {
                        throw new Error('You need to initialize the neural network first.');
                    }
                    // console.log('Forward propagation');
                    // console.log('Input: ' + input);

                    for (k = 0; k < this.layers.length; k++) {
                        outputs[k] = this.layers[k].forward(k === 0 ? input : outputs[k-1]);
                        // console.log('Output of layer k=' + k + ':');
                        // console.log(outputs[k]);
                    }
                    return outputs[outputs.length-1];
                },

                // Back propagation
                back: function(error) {
                    var k,
                        errors = [];

                    if (!this.layers) {
                        throw new Error('You need to initialize the neural network first.');
                    }
                    // console.log('Back propagation');

                    for (k = this.layers.length-1; k >= 0; k--) {
                        errors[k] = this.layers[k].back(k === (this.layers.length-1) ? error : errors[k+1]);
                        // console.log('Error of layer k=' + k + ':');
                        // console.log(errors[k]);
                    }
                },

                // Performs learning using a stochastic gradient approach
                // N: number of iterations
                // samples: training samples as an array of tuples
                // lambda: regularization parameter (>= 0)
                // tau: rate for parameter update
                // mu: alignment parameter for tau (0 < mu < 1)
                learning: function(N, samples, lambda, tau, mu) {
                    var n,
                        s,
                        output,
                        psum,
                        v,
                        t,
                        lastLoss = Number.POSITIVE_INFINITY,
                        curLoss;

                    if (!this.layers) {
                        throw new Error('You need to initialize the neural network first.');
                    }

                    for (n = 0; n < N; n++) {
                        console.info('Iteration ' + n);

                        // Backup current parameters
                        this.layers.forEach(function(layer) {
                            layer.backup();
                        });

                        // Reset current loss
                        curLoss = 0;

                        // For each training sample
                        for (s = 0; s < samples.length; s++) {
                            // Forward propagation
                            output = this.forward(samples[s][0]);

                            // Calculate error and loss (quadratic loss or softmax)
                            psum = 0;
                            if (this.softmax) {
                                for (t = 0; t < output.length; t++) {
                                    psum += Math.exp(output[t]);
                                }
                            }
                            v = new Array(output.length);
                            for (t = 0; t < output.length; t++) {
                                if (this.softmax) {
                                    v[t] = Math.exp(output[t]) / psum;
                                    if (samples[s][1][t] === 1) {
                                        v[t] -= 1;
                                    }
                                    curLoss += Math.abs(v[t]);
                                }
                                else {
                                    v[t] = output[t] - samples[s][1][t];
                                    curLoss += (0.5 * Math.pow(v[t], 2));
                                    // console.log('output: ' + output[t] + ' sample: ' + samples[s][1] + ' loss: ' + (0.5 * Math.pow(v[t], 2)));
                                }
                            }

                            // Back propagate error into network
                            this.back(v);

                            // Regularization
                            this.layers.forEach(function(layer) {
                                layer.regularization(2, lambda); // L2 regularization
                            });

                            // Parameter update
                            this.layers.forEach(function(layer) {
                                layer.update(tau);
                            });
                        }

                        console.info('Loss: ' + curLoss);
                        if (curLoss >= lastLoss) {
                            // restore last parameters from backup
                            this.layers.forEach(function(layer) {
                                layer.undo();
                            });

                            // align tau
                            tau *= mu;
                            console.info('Undo. New tau: ' + tau);
                        }
                        else {
                            lastLoss = curLoss;
                        }
                    }
                }
            };

            // Tests
            Tests = [
                // simple creation of a network, forward and backpropagation
                function() {
                    var nn = Object.create(NeuralNetwork);
                    nn.init(1, 2, 3, 1);
                    nn.forward([1]);
                    nn.back([0.5]);
                    return nn;
                },

                // a linear function (2x)
                function() {
                    var samples = [
                        [[1], [2]],
                        [[2], [4]],
                        [[3], [6]],
                        [[4], [8]],
                        [[5], [10]]
                    ];
                    var nn = Object.create(NeuralNetwork),
                        N = 10,
                        lambda = 0.1,
                        tau = 0.1,
                        mu = 0.5;
                    nn.init(1, 1);
                    nn.learning(N, samples, lambda, tau, mu);
                    return nn;
                },

                // AND example
                function() {
                    var samples = [
                        [[0, 0], [0]],
                        [[1, 1], [1]],
                        [[0, 1], [0]],
                        [[1, 1], [1]],
                        [[1, 0], [0]],
                        [[1, 1], [1]]
                    ];
                    var nn = Object.create(NeuralNetwork),
                        N = 1000,
                        lambda = 0.0,
                        tau = 0.1,
                        mu = 0.5;
                    nn.init(2, 1);
                    nn.setActivationFunction(ActivationFunctions.sigmoid);
                    nn.learning(N, samples, lambda, tau, mu);
                    return nn;
                },

                // XOR example
                function() {
                    var samples = [
                        [[0, 0], [0]],
                        [[0, 1], [1]],
                        [[1, 0], [1]],
                        [[1, 1], [0]]
                    ];
                    var nn = Object.create(NeuralNetwork),
                        N = 1000,
                        lambda = 0.0,
                        tau = 0.1,
                        mu = 0.5;
                    nn.init(2, 2, 1);
                    nn.setActivationFunction(ActivationFunctions.sigmoid);
                    nn.learning(N, samples, lambda, tau, mu);
                    return nn;
                },

                // a Cosine function
                function() {
                    var nn = Object.create(NeuralNetwork),
                        N = 1000,
                        lambda = 0.1,
                        tau = 0.01,
                        mu = 0.5,
                        samples = [],
                        i,
                        j;
                    for (i = 0, j = 0; i < 7; i += 0.01, j++) {
                        samples[j] = [[i], [0.5*(Math.cos(i)+1)]];
                    }
                    nn.init(1, 20, 5, 1);
                    nn.setActivationFunction(ActivationFunctions.sigmoid);
                    nn.learning(N, samples, lambda, tau, mu);
                    return nn;
                }
            ];
            // run tests like this:
            // Tests[4]();
        </script>

        <!-- AND example -->
        <script>
            document.getElementById('ex1-button').onclick = function() {
                eval(document.getElementById('ex1-textarea').value);
            };
        </script>

        <!-- This is only needed for the interactive chart examples: -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/1.0.2/Chart.js"></script>
        <script src="https://dima117.github.io/Chart.Scatter/Chart.Scatter.min.js"></script>

        <!-- Cosine example -->
        <script>
            document.getElementById('ex2-button').onclick = function() {
                // var nn = Tests[4]();
                eval(document.getElementById('ex2-textarea').value);
                var labels = [];
                var cosineData = [];
                var nnData = [];
                for (var i = 0, j = 0; i < 7; i += 0.1, j++) {
                    labels[j] = i.toFixed(2);
                    cosineData[j] = 0.5*(Math.cos(i)+1);
                    nnData[j] = nn.forward([i])[0];
                }
                document.getElementById('ex2-output').style.display = 'block';
                var chart = new Chart(document.getElementById('ex2-output').getContext('2d'));
                var data = {
                    labels: labels,
                    datasets: [
                        {
                            label: "Cosine function",
                            fillColor: "rgba(220,220,220,0.2)",
                            strokeColor: "rgba(220,220,220,1)",
                            pointColor: "rgba(220,220,220,1)",
                            pointStrokeColor: "#fff",
                            pointHighlightFill: "#fff",
                            pointHighlightStroke: "rgba(220,220,220,1)",
                            data: cosineData
                        },
                        {
                            label: "NN output",
                            fillColor: "rgba(151,187,205,0.2)",
                            strokeColor: "rgba(151,187,205,1)",
                            pointColor: "rgba(151,187,205,1)",
                            pointStrokeColor: "#fff",
                            pointHighlightFill: "#fff",
                            pointHighlightStroke: "rgba(151,187,205,1)",
                            data: nnData
                        }
                    ]
                };
                chart.Line(data, {animation: false});
            };
        </script>

        <!-- Classification example -->
        <script>
            var filesInput = document.getElementById("ex3-file");
            filesInput.addEventListener("change", function(event) {
                // Init Chart
                document.getElementById('ex3-output').style.display = 'block';
                var chart = new Chart(document.getElementById('ex3-output').getContext('2d'));
                var data = [
                    {
                        pointColor: '#582BA2',
                        data: [{ x: 0, y: 0 }]
                    },
                    {
                        pointColor: '#E5533C',
                        data: []
                    },
                    {
                        pointColor: '#FFC91C',
                        data: []
                    },
                    {
                        pointColor: '#8EB027',
                        data: []
                    },
                    {
                        pointColor: '#094B35',
                        data: []
                    }
                ];
                var scatterChart = chart.Scatter(data, {animation: false, datasetStroke: false});
                var samples = [];
                var trainingset = [];
                var trainingset_onehot = [];
                var testset = [];

                // Process files
                var files = event.target.files; //FileList object
                for (var i = 0; i < files.length; i++) {
                    var file = files[i];
                    var reader = new FileReader();
                    reader.addEventListener("load", function(event) {
                        var text = event.target.result;
                        var numCategories = 0;

                        // For each Line - Read samples
                        var lines = text.split('\n');
                        for (var line = 0; line < lines.length; line++) {
                            var items = lines[line].split(' ');
                            if (items.length !== 3)
                                continue;
                            var x1 = items[0],
                                x2 = items[1],
                                y = items[2];
                            samples.push([[Number(x1), Number(x2)], [Number(y)]]);
                            if (Number(y) > numCategories) numCategories = Number(y);
                        }

                        var toOneHot = function(x) {
                            var result = [];
                            for (var u = 0; u < numCategories; u++) result[u] = (u-1 === x) ? 1 : 0;
                            return result;
                        };

                        // Split into training and test set
                        var shuffled = samples.slice(0), i = samples.length, temp, index;
                        while (i--) {
                            index = Math.floor((i + 1) * Math.random());
                            temp = shuffled[index];
                            shuffled[index] = shuffled[i];
                            shuffled[i] = temp;
                        }
                        trainingset = shuffled.slice(0, Math.floor(samples.length * 0.8));
                        testset = shuffled.slice(Math.floor(samples.length * 0.8));

                        // Draw training set
                        for (var j = 0; j < trainingset.length; j++) {
                            scatterChart.datasets[trainingset[j][1][0]-1].addPoint(trainingset[j][0][0], trainingset[j][0][1]);
                            trainingset_onehot[j] = [trainingset[j][0], toOneHot(trainingset[j][1][0])];
                        }
                        scatterChart.update();

                        // Now do the learning
                        console.log(trainingset_onehot);
                        var LResult = {
                            resultset: [],
                            numCorrect: 0,
                            numTotal: 0
                        }
                        var lresults = [];
                        for (var li = 0; li < 5; li++) {
                            /*var nn = Object.create(NeuralNetwork),
                                N = 1000,
                                lambda = 0.1,
                                tau = 0.01,
                                mu = 0.5,
                                softmax = true;
                            nn.init(2, 2, 2, numCategories);
                            nn.setActivationFunction(ActivationFunctions.sigmoid);
                            nn.learning(N, trainingset_onehot, lambda, tau, mu);*/
                            eval(document.getElementById('ex3-textarea').value);

                            // Draw test set
                            var numCorrect = 0,
                                numTotal = 0,
                                resultset = [];
                            for (var j = 0; j < testset.length; j++) {
                                numTotal++;
                                var test_x1 = testset[j][0][0];
                                var test_x2 = testset[j][0][1];
                                var test_y = testset[j][1][0];
                                var nn_output = nn.forward([test_x1, test_x2]);

                                if (softmax) {
                                    var psum = 0;
                                    for (var oi = 0; oi < nn_output.length; oi++) {
                                        psum += Math.exp(nn_output[oi]);
                                    }
                                    for (var oi = 0; oi < nn_output.length; oi++) {
                                        nn_output[oi] = Math.exp(nn_output[oi]) / psum;
                                    }
                                }

                                var output_y = 0;
                                var max_nn_output_val = Number.NEGATIVE_INFINITY;
                                for (var oi = 0; oi < nn_output.length; oi++) {
                                    if (nn_output[oi] > max_nn_output_val) {
                                        max_nn_output_val = nn_output[oi];
                                        output_y = oi + 1;
                                    }
                                }
                                var correct = test_y === output_y;
                                console.log('(' + test_x1 + ',' + test_x2 + ') true:' + test_y + ' output:' + nn_output + ' -> ' + output_y + (correct ? ' CORRECT!' : ''));
                                if (correct) numCorrect++;
                                resultset.push([test_x1, test_x2, output_y-1]);
                                //scatterChart.datasets[output_y-1].addPoint(test_x1, test_x2, 2);
                            }
                            lresult = Object.create(LResult);
                            lresult.numCorrect = numCorrect;
                            lresult.numTotal = numTotal;
                            lresult.resultset = resultset;
                            lresults.push(lresult);
                        }
                        var max_lresult, max_lresult_numCorrect = 0;
                        for (var li = 0; li < lresults.length; li++) {
                            if (lresults[li].numCorrect > max_lresult_numCorrect) {
                                max_lresult = lresults[li];
                                max_lresult_numCorrect = lresults[li].numCorrect;
                            }
                        }
                        for (var rsi = 0; rsi < max_lresult.resultset.length; rsi++) {
                            var curRes = max_lresult.resultset[rsi];
                            scatterChart.datasets[curRes[2]].addPoint(curRes[0], curRes[1], 2);
                        }
                        scatterChart.update();
                        document.getElementById('ex3-result').innerHTML =
                            'Small dots: Training set<br>' +
                            'Bold dots: Test set with NN classification<br><br>' +
                            '<b>Result</b>:<br>' +
                            'Correct: ' + max_lresult.numCorrect + ' of ' + max_lresult.numTotal + '<br>' +
                            'Accuracy: ' + (max_lresult.numCorrect/max_lresult.numTotal).toFixed(2);
                    });
                    reader.readAsText(file);
                }
            });
        </script>
    </body>
</html>
